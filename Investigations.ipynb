{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Data Reusability Project\n",
    "\n",
    "This notebook is an informal investigation into the technologies needed to take the data contained in \"open data\" publications from the UK Department of Health. This will allow researchers to automate computations and respond more speedily to changes.\n",
    "\n",
    "Some of this is ugly, some of it will doubtless be unnecessary, but it shows at least some of the preliminary work that goes into getting one's thinking straightened out about a particular program or set of programs.\n",
    "\n",
    "Even this published product has been subject to much revision and polishing to eliminate simple experiments and code written purely to understand certain aspects of various package's behavior.\n",
    "My bad habit is to delet this code before it is committed to a source control system, but I would recommend that you inculcate better habits than me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openpyxl as xl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this software cannot read \".xls\" files. `wb = xl.load_workbook(\"data/gpearnextime.xls\")` raises an exception, so I toook the quick route and converted it to a \".xlsx\" file with Excel before further processing.\n",
    "\n",
    "It might be worth investigating the older `xlrd` module, which can read \".xls\" files (though sadly there appears\n",
    "to be no easy way to write them out as \".xslx\" files which I had hoped `xlwt` might have provided. I suspect that there will be an easy fix for this, but I'll need to speak to Chris Withers. It may also be possible to simply use `openpyxl` for `.xlsx` files or `xlrd` for `.xls` files.\n",
    "\n",
    "Since this is an experimental project, I punted on this issue and manually performed a function that does not seem amenable to early automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wb = xl.load_workbook(\"data/gpearnextime.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wb.sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws = wb.get_sheet_by_name('1a. GPMS Cash Terms ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws[\"B7\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1, 200):\n",
    "    print(ws[\"B{}\".format(i)].value, ws[\"C{}\".format(i)].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the date values and the footnote numbers run together to give a single string value.\n",
    "That means some parsing has to be applied to separate it into a `(date, footnote)` pair, whose\n",
    "second member will be `None` if no notes apply.\n",
    "From an openness point of view it would be much better to have a separate column for the footnotes that should be applied to the row.\n",
    "Then again, from an openness point of view it would be better not to use Excel spreadsheets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that may not be as useful as I thought. It would probably be eaiser to maintain the column values as part ofthe processing logic.\n",
    "\n",
    "(This was borne out when I wrote a non-terminting loop when experimenting with the code below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws[\"B3\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def year_refs(s):\n",
    "    \"\"\"Separate the year string into the year plus the list of references\"\"\"\n",
    "    return s[:7], s[7:].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws[\"d81\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_val(val):\n",
    "    return 0 if val == \"-\" else val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_val(32.456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_val(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3 == \"banana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = ws[\"B3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably a good idea to look at how we can find the relevant areas in a worksheet, then analyze the content of those areas (which will vary in size, increasing as the years go by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws[\"B3\"].value # Sheet heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws[\"B5\"].value # Table heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cells = ws.get_cell_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "cols_in_row = defaultdict(list)\n",
    "\n",
    "for cell in cells:\n",
    "    if cell.value is not None:\n",
    "        cols_in_row[cell.row].append(cell.column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_row = max(c for c in sorted(cols_in_row.keys()))\n",
    "max_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that cell J43 has a spurious value that should really be ignored. Wonder how long that's been there and who knows it is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_in_row[43].remove('J')\n",
    "cols_in_row[43]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "max_col = max(c for r in range(rows) for c in cols_in_row[r])\n",
    "max_col"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "cols = ord(max_col)-ord(\"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pixels = [] # straight list of pixel values for graphic\n",
    "matrix = []\n",
    "#print(\"  \".join(list(\"ABCDEFG\"))) # Column headings\n",
    "for row_num in range(max_row):\n",
    "    cols = cols_in_row[row_num]\n",
    "    row_string = []\n",
    "    row_matrix = []\n",
    "    for col_name in \"ABCDEFG\":\n",
    "        row_string.append(\"*\" if col_name in cols else \" \")\n",
    "        row_matrix.append(col_name in cols)\n",
    "    #print(\"  \".join(row_string))\n",
    "    matrix.append(row_matrix)\n",
    "    pixels += [1-p for p in row_matrix] + [1]*7 # add pixel row plus blank row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.new(\"1\", (7, 198*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im.putdata(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im.resize((7*20, 198*4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization makes the pattern of the tables more obvious.\n",
    "Each table begubs with a row with a single cell, followed by two cells with six rows and a number of rows with five cells.\n",
    "Now, it would be possible to construct a vector with the number of cells in each row, and then search\n",
    "that for patterns characteristic of the start of a table.\n",
    "Whenever you find yourself thinking \"pattern,\" though, it's worth considering using Python's `re`\n",
    "regular expression-based pattern-matching algorithm.\n",
    "Since no row has more than seven cells we can construct a ___string of row lengths___ and then\n",
    "use pattern matching to find the starting positions of the tables.\n",
    "The task then simplifies to finding the string `\"1665\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_sizes = \"\".join(str(sum(x for x in row)) for row in matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "for m in re.finditer(\"(1665)\", str_sizes):\n",
    "    print(m.span()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "Maybe there's some easier way to determing the shape without all these complex manipulations.\n",
    "I don't know about you, but I often find my second approach to a problem is more intelligent\n",
    "than the first (that's why we are often recommended to write a prototype _and then throw it away_).\n",
    "So consider everything above as prototypical, offering insight into the necessary analysis but using a horribly inefficient algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ws.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_counts =[sum(cell.value is not None for cell in column) for column in ws.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_cols = [i for (i, ct) in  enumerate(col_counts) if ct > 1]\n",
    "valid_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_counts =[sum(cell.value is not None for cell in row) for row in ws.rows]\n",
    "valid_rows = [i for (i, ct) in  enumerate(row_counts) if ct > 0]\n",
    "len(valid_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ncols = len(valid_cols)\n",
    "max_row_num = max(valid_rows)\n",
    "pixels = []\n",
    "row_counts = []\n",
    "for row in range(max_row_num):\n",
    "    cell_strings = []\n",
    "    row_pixels = []\n",
    "    for col in valid_cols:\n",
    "        value = ws.rows[row][col].value\n",
    "        row_pixels.append(value is None)\n",
    "    pixels += row_pixels*3 + [1]*ncols # blank line\n",
    "    row_counts.append(sum(1-pixel for pixel in row_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = Image.new(\"1\", (ncols, 4*(max_row_num)))\n",
    "im.putdata(pixels)\n",
    "im.resize((14*ncols, 8*(max_row_num+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that this techmique can be fairly effectively used to get an idea of the shape of a worksheet.\n",
    "The next step will be to turn that into a function with the worksheet as a parameter, and apply it to all the sheets on a workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize(ws):\n",
    "    col_counts =[sum(cell.value is not None for cell in column) for column in ws.columns]\n",
    "    valid_cols = [i for (i, ct) in  enumerate(col_counts) if ct > 1]\n",
    "    row_counts =[sum(cell.value is not None for cell in row) for row in ws.rows]\n",
    "    valid_rows = [i for (i, ct) in  enumerate(row_counts) if ct > 0]\n",
    "    ncols = len(valid_cols)\n",
    "    max_row_num = max(valid_rows)\n",
    "    pixels = []\n",
    "    row_counts = []\n",
    "    for row in range(max_row_num):\n",
    "        cell_strings = []\n",
    "        row_pixels = []\n",
    "        for col in valid_cols:\n",
    "            value = ws.rows[row][col].value\n",
    "            row_pixels.append(value is None)\n",
    "        pixels += row_pixels*3 + [1]*ncols # blank line\n",
    "        row_counts.append(sum(1-pixel for pixel in row_pixels))\n",
    "    im = Image.new(\"1\", (ncols, 4*(max_row_num)))\n",
    "    im.putdata(pixels)\n",
    "    return im.resize((14*ncols, 8*(max_row_num+1))), row_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []; row_counts = []\n",
    "for ws in wb.worksheets:\n",
    "    if ws.sheet_state != \"hidden\": # exclude hidden sheets\n",
    "        image, counts = visualize(ws)\n",
    "        images.append(image)\n",
    "        row_counts.append(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEFT_MARGIN = 4\n",
    "im_width = sum(i.size[0] for i in images)+(len(images)-1)*LEFT_MARGIN\n",
    "im_height = max(i.size[1] for i in images)\n",
    "im_width, im_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(row_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_widths = [max(c) for c in row_counts]\n",
    "table_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_offset = 0\n",
    "big_image = Image.new(\"1\", (im_width, im_height), 1)\n",
    "for i, im in enumerate(images):\n",
    "    big_image.paste(im, (x_offset, 0))\n",
    "    x_offset += im.size[0]+LEFT_MARGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws = wb.worksheets[2]\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Page header is in B3 always?\n",
    "page_header = ws[\"B3\"].value\n",
    "print(page_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts_string = \"\".join(str(n) for n in row_counts[2])\n",
    "counts_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for the pattern `\"1665\"`\\* in `counts_string` finds a six-column table.\n",
    "The first line is the name of the table.\n",
    "The second line is the column headings.\n",
    "The remainder of the table is a number of repeating groups.\n",
    "The first column is special because unchanged values aren't repeated (which is why subsequent lines only have five elements).\n",
    "While this is helpful for the human reader's comprehension it has to be corrected for the computer.\n",
    "\n",
    "\\* Yes, this is a fix - that string was chosen because I knew there were six columns in the tables.\n",
    "We may or may not get to the computation of the number of columns later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_starts = [x.start(0) for x in re.finditer(\"1665\", counts_string)]\n",
    "table_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_lens = [x.end(\"X\")-x.start(\"X\") for x in re.finditer(\"16(?P<X>65[56]+)\", counts_string)]\n",
    "table_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_of_tables = len(table_starts)\n",
    "number_of_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a little work on the first table.\n",
    "Also, let's learn how to access the elements we need in order to construct a usable data source.\n",
    "The crucial facts for each table are the number of groups, the number of rows in each group\n",
    "and the number of columns in the table.\n",
    "When you think about it this is simply a description of a three-dimensional structure.\n",
    "The first table reports figures over the whole UK.\n",
    "The remainder analyze that information geographically, adding a fourth dimension to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a little work on the first table to learn what we'll need to do in the general case.\n",
    "\n",
    "Firstly, let's see how to access the various \"chunks\" of the table, beginning with its title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_row = table_starts[0]\n",
    "table_len = table_lens[0]\n",
    "ws[\"B5\"].value, ws[\"B5\"], ws.columns[1][4], ws.columns[1][start_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_cell = ws.columns[1][start_row]\n",
    "title_cell.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to extract the column names, which are on the row following the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_cols = 6\n",
    "# was int(counts_string[start_row+1]), but that depended on arcane knowledge in the building of the pattern\n",
    "headers = [c.value for c in ws.rows[start_row+1][1:table_cols+1]] # really should have computed that \"6\" from the pattern ...\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a cheesy way to work out how many groups there are\n",
    "pat = \"(?P<X>(65+)+)\"\n",
    "m = re.search(pat, counts_string, start_row+2)\n",
    "assert m.groups(0)[0].replace(m.groups(0)[1], \"\") == \"\" # only true for fixed groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_count = len(m.groups(0)[0])//len(m.groups(0)[1])\n",
    "group_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_len = table_len//group_count\n",
    "group_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "first_data_row = start_row+2\n",
    "dataframes = []\n",
    "for data_start_row in range(first_data_row, first_data_row+table_len, group_len):\n",
    "    group_cells = [[ws.rows[row][col].value for col in range(1, table_cols+1)]\n",
    "                   for row in range(data_start_row, data_start_row+group_len)]\n",
    "    group = pd.DataFrame(group_cells, columns=headers)\n",
    "    group[headers[0]] = group[headers[0]][0]\n",
    "    dataframes.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_frame = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_frame.index = range(table_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "big_frame[\"Estimated Population\"][22:33].replace(\"-\", np.NaN).interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "js = big_frame.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_json(js)[headers].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_json(js)[headers].sort()[headers[2:]].replace(\"-\", np.NaN)-big_frame[headers[2:]].replace(\"-\", np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_frame[headers[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rl_charset = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "def rl_dig(i):\n",
    "    return rl_charset[i]\n",
    "\n",
    "def dig_rl(c):\n",
    "    return rl_charset.index(c)\n",
    "\n",
    "# testing, even!\n",
    "for c in rl_charset:\n",
    "    assert rl_dig(dig_rl(c)) == c\n",
    "\n",
    "for i in range(len(rl_charset)):\n",
    "    assert dig_rl(rl_dig(i)) == i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_table(ws, table_width, row_counts, start_row):\n",
    "    counts_string = \"\".join(rl_dig(n) for n in row_counts)\n",
    "    print(counts_string)\n",
    "    title = ws.columns[1][start_row].value\n",
    "    print(title)\n",
    "    headers = [c.value for c in ws.rows[start_row+1][1:table_width+1]]\n",
    "    pat_string = \"1{}((?P<X>{}{}+)+)\".format(counts_string[start_row+2],\n",
    "                                             counts_string[start_row+2],\n",
    "                                             counts_string[start_row+3], )\n",
    "    print(pat_string)\n",
    "    pat = re.compile(pat_string)\n",
    "    m = pat.match(counts_string, start_row)\n",
    "    whole_group = m.groups(0)[0]\n",
    "    subgroup = m.groups(0)[1]\n",
    "    group_len = len(subgroup)\n",
    "    group_count = len(whole_group)//group_len\n",
    "    print(title, pat_string, whole_group, subgroup, group_count, group_len)\n",
    "    assert whole_group == group_count*subgroup\n",
    "    import pandas as pd\n",
    "    first_data_row = start_row+2\n",
    "    dataframes = []\n",
    "    print(\"range:\", first_data_row, first_data_row+table_len, group_len)\n",
    "    for group_num in range(group_count):\n",
    "        data_start_row = first_data_row+group_num*group_len\n",
    "        print(\"starting at:\", data_start_row)\n",
    "        print(\"group len:\", group_len)\n",
    "        group_cells = [[c.value for c in ws.rows[row][1:table_width+1]]\n",
    "                       for row in range(data_start_row, data_start_row+group_len)]\n",
    "        group = pd.DataFrame(group_cells, columns=headers)\n",
    "        group[headers[0]] = group[headers[0]][0]\n",
    "        dataframes.append(group.replace(\"-\", np.NaN))\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "big_frames = [extract_table(ws, table_widths[2], start_row) for start_row in table_starts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "table = pd.concat(big_frames)\n",
    "table.index = range(len(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_widths.index(22), len(table_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws2 = wb.worksheets[19]\n",
    "row_counts[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_tbl = extract_table(ws2, 10, row_counts[18], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tbl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tbl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tbl[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat(new_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
